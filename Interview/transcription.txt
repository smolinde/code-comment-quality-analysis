Okay, all right. Thank you very much for taking the time to interview me. I would like to talk to you today about Code Comments and what the meaning of Code Comments is for a project. How your opinion on the topic of how Code Comments can be generated and made by AI. I have prepared six questions and I think you can just say your opinion as an experienced software developer. The first question would be very simple and general. How important are Code Comments in large scale? How important are Code Comments in large scale in software projects? That's a good question to start with, because there are very different philosophies. I actually belong to the person who says there should only be as many comments in the software as is really necessary and the software should be written in such a way that it is self-explanatory. That means that we choose function names that are self-explanatory. And then I have to write the function name. I should not describe the function in detail. I should not just number a function or something like that. I should just write this function adds A with B and then I have two transfer values ​​that are called A and B. And then it is relatively clear what this function does. Then I don't need to comment on it much. And then there is a second paradigm that I find very interesting. I think it is that you should not comment on what you are doing, but on why you are doing something. And that's exactly the problem where you say, hey, it will be difficult to use automatically generated comments. Because what you do, you get out relatively well automatically. But why certain things are done, that is under circumstances only in the heads of the respective developers. All right, that also plays perfectly into the second question that I have prepared. Namely, what are good code comments for you? How would you define them, so to speak? So you said that these are code comments that are really necessary at first. But are there maybe other aspects if they are necessary? What is a good code comment then? Yes, so as I said, a code comment should always contain why you are doing something and not necessarily what you are doing right now. Because you should assume that a developer who looks at the source understands what is being done. There are certain things where you can then say in a few words what you are doing right now, because it is now very complicated for certain reasons. So that you say you have a very long function or whatever that does not close at first glance. Then you can think about whether you can then document what you are doing right now. In the rule of thumb, I am always a friend of saying we document why we are doing something. And I am also a very great advocate of the fact that I find it worse when a false comment is there than when no one is there. Because then you simply lean on the wrong security and that comes up much later. So I myself was once involved in a project in which we posted that comments are being written. That means you could then in the ID that we used at the time, the Visual Studio, you could then indicate that each function had to have a description. And also every transfer parameter had to be described. And that just led to people copying functions that were unnamed but did not adapt the comments. And then the comments were no longer usable at all. And that goes exactly the opposite. And that's why I'm always, I'm a very great advocate. As little as possible, as much as necessary and always to say why I'm doing something. And then also accordingly the comments, if you write them, if you keep them necessary at a certain point, as short as possible. So I understand that correctly. So don't let them slip away for a long time, write a novel. So less documentation, so really a short and concise sentence. Why you do something at a certain point. Exactly. Although this is always a bit in context. So if I now have some function that has some algorithm, then of course I can write about what this algorithm does. On the other hand, I say, yes, why do I not recognize the name of the function, what this algorithm does? So then you have to think about it. Hey, does the comment not solve a problem? Does it already have a name? And could it solve it on another level? You just have to think about that. Okay, that makes a lot of sense. Exactly. Then there would be another question that also fits perfectly into the context here. Were there certain moments when you didn't write code comments, although you might want to write them? Or in general, where were there times when you let them go? And what were the reasons for that? So except that it was not necessary at this point, for example, where the code itself was explained, but maybe another reason. What I have in my head is, for example, time pressure. That is, in the project, for example, there was a moment when it was said, here is the deadline. Until then, the code has to be in production. And that's why code comments were omitted. Has there ever been something like that? Yes, definitely. Yes, definitely. I wouldn't necessarily call it a deadline. I don't think the time pressure is the factor at all, because you actually wrote such a comment relatively quickly. I mean, it's not two sentences or anything, you wrote it quickly. I think you just have to see that when developing, there is a lot of trying out. Where you say, I just test things out, I think about something. I have a theoretical construct, of course. I bring it to the source code, then I test it. That doesn't work then. Okay, then I'll rebuild it. And you do that all the time. It's an iterative process. And that means it makes little sense to write this comment right at the beginning, because so much is still changing in the way you coded it, that you would have to adjust the comment all the time. And when you finally have it running, then you want to move on to the next one. So you've completed this task and then you get busy with it. I don't think you're that busy with it anymore. I think many don't have the discipline to say, okay, now I'm thinking about how I should comment on it. And then there's the fact that I've completely overwhelmed this problem I have. I've been dealing with a function for several hours now, under circumstances. I've completely overwhelmed it. And for me, it's all totally logical. And then to switch to a person who might read it for the first time. I don't think very many do that. And I have to be honest, I do that too. Too rarely. Okay. That means that's also the problem somewhere, that you don't change the perspective and that's why you leave the code comment with the thought that it's logical and clear and understandable anyway. Yes. So that's the thing. Yes, exactly. Okay, great. Yes, that's a very good basis for code comments itself. And with the development today that there are large language models, the question arises in both science and industry to what extent such tools as ChatGPT could support this entire process. And the next question would be, to what extent do you think that a large language model is a good tool for this? So that a large language model could not only write the code itself, but only comment on it completely or partially automate it? That's hard to judge, because on the one hand you always have these experiences where you say, how can this LLM know that? So we've tested it with the comments and so on. And where you say, hey, where does this LLM really have this knowledge to write the comment like this? Where you really wonder where that comes from. And then there are really things where comments come out again, where you think, well, what went wrong there? So that means it's definitely an relief, but I think it's always very, very contact-dependent. So I think it's also there. Without a doubt. And that's where it is without me really having valid numbers or reliable numbers. But I think that's where everything that can be explained so technically is very good now. So really explaining such an algorithm. So what does such an algorithm do step by step? That works really well. And then there are things, of course, that you can't know. So if you now have to put a value of the field on five, just because there is some foreign system that says it always has to be on five, then LLM knows that. That's just how it is. LLM just doesn't know. Then you can just write in, hey, here the value is set to five. But often this feeling really prevails. That's damn good what comes out of it. Yes, that's exactly the point. On the one hand, there is the hallucination. That's a problem with large language models. And on the other hand, of course, the very question. If this is a very project-specific thing, of course, the large language model can't name any concrete things at the moment or maybe not write the appropriate code comment just because it doesn't know the context. You could theoretically solve that with a pre-prompt, so to speak, that you write the context here and there and then adjust the comment in that direction. And that would be my question. Have you ever tried to do that in a project? And if so, the code comments that were then created, did they meet your expectations well? Or did you say, no, I still had to adjust a lot manually? That's the question now, how far you want to take code comments. So I can remember one thing where we really looked at a project that we didn't develop ourselves. And that's kind of how we got there. And that's kind of how we got there. We then sort of chased that through GitHub Copilot and asked GitHub Copilot questions about this project. And then he really asked us, where is the authentication being carried out by the user? And then he could really show us where the authentication is carried out in the source code. Of course, he didn't create the comments in the source code. That wasn't the challenge either. But he did create this context somewhere in the source code. And that worked very well. So that means we were able to navigate very well through this source code. But then you have to say again, it was necessarily necessary that we as developers also understand what is in the source code. Because at some point, what you just said, the system started hallucinating. So according to the motto, if you drive into the corner, there is an answer whether it is true or not. The thing doesn't really matter. And that means the more detailed the questions became, the further we went down and said, hey, where is the authentication? I don't know, I don't know which authentication provider is being used and so on. And at some point it really just started to invent source code that was not even in the project. So we always checked it and said, this and that was done. And then we looked at it and then it was done there too. And at some point the thing was completely wrong, because we asked more and more questions and then just presented source code that was not even in the project. Okay, that's interesting. That was for the first time. For the entry and for the basic understanding it was very good. But you always have to check it, that's for sure. But that's practically the direction, not writing code comments, but having existing code, existing artifacts described and then pointing to somewhere and summarizing accordingly. Exactly, although it goes in the same direction. So a source comment is to summarize existing source code in some way or another. Just that we said now, we don't write these comments into the source code. But for us it was this explanation, just to understand the project better and faster. Exactly, so the idea is also a bit that you reduce the time with a large language model in which you understand something fundamentally. So it's also a bit the goal of auto-generated code comments. And the last planned question. Yes. I have a few more now. For later, but now the last prepared. In your opinion, which code comments are better today? Those written by people or those generated by the machine, by a large language model? So I think about the whole mass. Exactly, so not on the project in general. Exactly. I would, I think, say that probably the whole mass. Exactly. I would say that probably the automatically generated ones are better. Okay, exactly, because that's just a bit of an impression that comes from the numbers of the experiment. In addition, it was an exciting finding. It is still the question of indistinguishability. Namely, can a person separate which code comment was created by LLM or people? And the experiment showed that it is correspondingly. People are clueless and do not know who wrote the code comment at the end. Yes. We just covered the numbers. And exactly. My, so another question here would be, let's say in the companies or in the company, it develops in the direction that there are large language models that are specifically designed for this. Now we have Copilot maybe as an example. But a specific system that specializes only in writing code comments. What expectations or requirements would you have for such a system? What would be, how would such a system look ideal for you? How would that look ideal? Well, it would just write the comments on the fly. Yes. While I'm coding, it would write the comments. Live, so to speak. Yes, live, I think. Yes, it's a difficult question. That's true. Yes, that's how I would imagine it. But I always try to. So I'm just thinking. I think. LMS extremely helpful. So especially when you have to write concepts, for example. Yes, then they are really very helpful. You can just type in a question and you'll get a lot of information. But you just have to know yourself. What just happens there. You have to know the background. In my opinion, you have to have it yourself. To be able to understand when the system starts to hallucinate. And that's the question I'm just asking myself. So it would be totally cool if I coded. And at the same time the comments would be written. So I'm coding and see how the comments are written. That would be something that would just come in super. Could also present super. But the question is how you get this review. That the developer still reads the comments. To make sure that the right comments are also. That's just the question. I can't really answer that. Yes, that's actually always difficult. Because the expertise is in the end. Anyway, extremely important. Because an LLM is still an instrument. A tool that you use. Have to learn. And that's just. That's what you can do in that case. I think without expertise. Not so easy. What I'm thinking about now. If such a live system, for example. Flag your own comments. For example, say okay. The machine is at that comment. For example, 100% sure. And at that 50% sure. At the other it would say. Here I only have 20% confidence. So to speak. And then accordingly. Maybe also color or somehow mark. So that at certain points. Where the model itself notices. That the probability that this is now. The perfect code comment is. This probability is low. That the developer again. The developer herself again. Read over manually. Yes, that's not a bad idea. Yes. Ultimately. Would be the primary goal. Of course not the software developer. To replace. But rather. Give him or her the time. Which otherwise on this manual. The effort of the documentation. So that's the goal. But basically you say. That machine-made. Code comments. So from large language models. So to speak. Are competitive. With the. What is written by people. Yes, all right. Yes, great. I actually have no more. More concrete questions. Maybe you have some. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. You already said. That the result is. The people are practically not able to recognize. Whether it is from. Machine or not. And that. I think. You said. That the machine generally. Are judged better than the. From people. Exactly. I had six. Quality criteria. In the survey. Altogether. Installed. And. It is. So that. The average. With. All. and 4 out of 6 significantly higher. That means that the statistical tests said that it is clearly higher here than in the human comments. That means that all were rated higher and with 4 out of 6 criteria it was particularly high. With the code comment length there was no significant difference. Well, the code comment length is the same for humans and machines. But the others that are more useful, were then rated higher by the machine. I don't know, did I send you the photo? I have to check it. I don't remember that. I definitely have an image with a bar diagram where you can see it quite well. And that's such an exciting result. I think it's worth it to support the quantitative statements. Some things are definitely different, but that's really good. And I would like to thank you for that. Yes, gladly. How many participants did you have now? 9. 9 in total. But that's not bad. Simply because it has increased inflation. Because there were many questions about the part. That means there were a total of 600 or 700 responses. So really individual points. There were 9 participants and 1 or 2 participants. But in total there were many answers. That's why you could already see a certain tendency. And fun fact, the statistics between the 8th and 9th participant has hardly changed. But on the contrary, the indistinguishability converges by 50%. That means people guess practically whether the person was a machine. And the other values, the quality assessments, they change little to none. So yes, the number of the tested test subjects is small, but the results are still speaking for themselves. Yes. Yes, cool. All right, then I'll stop the recording here. So, end recording.